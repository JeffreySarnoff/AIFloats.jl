# Floating-Point Types Consistent with P3109

The [IEEE SA P3109 Working Group](https://standards.ieee.org/iee7e/3109/11165/)
 is drafting a standard for floating-point formats used in machine learning.

Here are floating-point types consistent with the content of the current draft.<br>
However, until the IEEE issues the Standard, *there may substantive changes.*

The most recent update of the publicly available **Interim Report** 
working draft standard defines a binary arithmetic and data format for machine learning-optimized domains, providing a consistent and flexible arithmetic framework optimized for Machine Learning Systems implemented in hardware and/or software. Having a shared standard improves interoperability.  These formats are designed to be efficient, consistent and highly performant."

This package, "FloatsForML.jl", is the first one of three that work together to provide a careful reference implementation for other's use and further the work of standard content validation.

For matters of consensus that the working group has made public, see [The Interim Report](https://github.com/P3109/Public/blob/main/IEEE%20WG%20P3109%20Interim%20Report.pdf).

# Floating-Point Types Consistent with P3109

The [IEEE SA P3109 Working Group](https://standards.ieee.org/iee7e/3109/11165/)
 is drafting a standard for floating-point formats used in machine learning.


"This standard defines a binary arithmetic and data format for machine learning-optimized domains, providing a consistent and flexible arithmetic framework optimized for Machine Learning Systems implemented in hardware and/or software. Having a shared standard improves interoperability.  These formats are designed to be efficient, consistent and highly performant."

This package, "FloatsForML.jl", is the first one of three that work together to provide a careful reference implementation for other's use and further the work of standard content validation.


 see [The Interim Report](https://github.com/P3109/Public/blob/main/IEEE%20WG%20P3109%20Interim%20Report.pdf).

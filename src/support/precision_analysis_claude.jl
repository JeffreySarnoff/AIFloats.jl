# generated by Claude Sonnet 4 in Research BETA mode 2025-06-08T10:49Z










"""
FloatingPointAnalysis0.jl

Comprehensive floating-point precision analysis toolkit for Julia.
Supports Float16, Float32, Float64, and BigFloat with generic programming patterns.

Author: Generated based on Julia best practices (2024-2025)
License: MIT
"""
module FloatingPointAnalysis0

using Printf

# Export all public functions and types
export MachineEpsilonInfo, ULPInfo, PrecisionAnalysis, FloatFormatInfo
export machine_epsilon_info, ulp_distance, ulp_analysis
export detect_precision_loss, detect_cancellation, analyze_rounding_error
export float_format_info, bit_analysis, special_value_info
export precision_bounds, numerical_stability_check
export compare_precision, format_analysis_report
export compute_machine_epsilon, measure_precision_loss, analyze_subtraction_stability

#=============================================================================
Core Data Structures
=============================================================================#

"""
    MachineEpsilonInfo{T<:AbstractFloat}

Container for machine epsilon analysis results.

# Fields
- `standard_eps::T`: Standard machine epsilon (difference between 1 and next float)
- `unit_roundoff::T`: Unit roundoff (ε/2, theoretical minimum relative error)
- `next_after_one::T`: Next representable number after 1.0
- `prev_before_one::T`: Previous representable number before 1.0
"""
struct MachineEpsilonInfo{T<:AbstractFloat}
    standard_eps::T
    unit_roundoff::T
    next_after_one::T
    prev_before_one::T
end

"""
    ULPInfo{T<:AbstractFloat}

Container for Unit in Last Place analysis results.

# Fields
- `ulp_value::T`: ULP at the given point
- `ulp_distance::Float64`: Distance in ULPs between two values
- `relative_error::Float64`: Relative error as fraction of ULP
"""
struct ULPInfo{T<:AbstractFloat}
    ulp_value::T
    ulp_distance::Float64
    relative_error::Float64
end

"""
    PrecisionAnalysis{T<:AbstractFloat}

Comprehensive precision analysis results.

# Fields
- `input_value::T`: Original input value
- `computed_value::T`: Computed result
- `theoretical_value::T`: Theoretical exact result (if available)
- `absolute_error::T`: |computed - theoretical|
- `relative_error::Float64`: Relative error magnitude
- `significant_digits::Int`: Number of accurate significant digits
- `precision_loss::Float64`: Fraction of precision lost
"""
struct PrecisionAnalysis{T<:AbstractFloat}
    input_value::T
    computed_value::T
    theoretical_value::T
    absolute_error::T
    relative_error::Float64
    significant_digits::Int
    precision_loss::Float64
end

"""
    FloatFormatInfo{T<:AbstractFloat}

IEEE 754 format characteristics for a floating-point type.

# Fields
- `type_name::String`: Name of the floating-point type
- `total_bits::Int`: Total number of bits
- `sign_bits::Int`: Number of sign bits (always 1)
- `exponent_bits::Int`: Number of exponent bits
- `mantissa_bits::Int`: Number of mantissa bits (including implicit bit)
- `bias::Int`: Exponent bias
- `min_exponent::Int`: Minimum exponent value
- `max_exponent::Int`: Maximum exponent value
"""
struct FloatFormatInfo{T<:AbstractFloat}
    type_name::String
    total_bits::Int
    sign_bits::Int
    exponent_bits::Int
    mantissa_bits::Int
    bias::Int
    min_exponent::Int
    max_exponent::Int
end

#=============================================================================
Machine Epsilon Analysis
=============================================================================#

"""
    machine_epsilon_info(::Type{T}) where {T<:AbstractFloat} -> MachineEpsilonInfo{T}

Comprehensive machine epsilon analysis for floating-point type T.

Computes both the standard definition of machine epsilon (difference between 1 and the 
next larger representable number) and the unit roundoff (half of machine epsilon, 
representing the theoretical bound on relative rounding error).

# Arguments
- `T::Type{<:AbstractFloat}`: Floating-point type to analyze

# Returns
- `MachineEpsilonInfo{T}`: Complete epsilon analysis

# Examples
```julia
julia> info = machine_epsilon_info(Float64)
julia> info.standard_eps
2.220446049250313e-16

julia> info.unit_roundoff  
1.1102230246251565e-16

julia> machine_epsilon_info(Float32).standard_eps
1.1920929f-7
```

# Mathematical Background
For IEEE 754 binary formats with precision p bits:
- Standard epsilon: ε = 2^(1-p) 
- Unit roundoff: u = ε/2 = 2^(-p)

# Implementation Notes
Uses Julia's built-in `eps()` function for accuracy and supports all floating-point types
including BigFloat through generic programming.
"""
function machine_epsilon_info(::Type{T}) where {T<:AbstractFloat}
    std_eps = eps(T)
    unit_roundoff = std_eps / T(2)
    next_val = nextfloat(one(T))
    prev_val = prevfloat(one(T))
    
    return MachineEpsilonInfo{T}(std_eps, unit_roundoff, next_val, prev_val)
end

machine_epsilon_info(x::T) where {T<:AbstractFloat} = machine_epsilon_info(T)

"""
    compute_machine_epsilon(::Type{T}; method::Symbol=:iterative) where {T<:AbstractFloat} -> T

Alternative machine epsilon computation using iterative or bit manipulation methods.

# Arguments  
- `T::Type{<:AbstractFloat}`: Target floating-point type
- `method::Symbol`: Computation method (`:iterative`, `:theoretical`, `:nextfloat`)

# Returns
- `T`: Machine epsilon value

# Examples
```julia
julia> compute_machine_epsilon(Float64; method=:iterative)
2.220446049250313e-16

julia> compute_machine_epsilon(Float32; method=:theoretical)  
1.1920929f-7
```
"""
function compute_machine_epsilon(::Type{T}; method::Symbol=:iterative) where {T<:AbstractFloat}
    if method == :iterative
        # Classic iterative method
        epsilon = one(T)
        while (one(T) + epsilon/T(2)) != one(T)
            epsilon = epsilon / T(2)
        end
        return epsilon
        
    elseif method == :theoretical
        # Theoretical calculation for IEEE 754 formats
        if T == Float16
            return T(2)^(-10)  # 2^(1-11) where 11 is mantissa bits
        elseif T == Float32
            return T(2)^(-23)  # 2^(1-24) where 24 is mantissa bits  
        elseif T == Float64
            return T(2)^(-52)  # 2^(1-53) where 53 is mantissa bits
        else
            # Fallback for BigFloat and other types
            return eps(T)
        end
        
    elseif method == :nextfloat
        # Using nextfloat function
        return nextfloat(one(T)) - one(T)
        
    else
        throw(ArgumentError("Unknown method: $method. Use :iterative, :theoretical, or :nextfloat"))
    end
end

#=============================================================================
ULP (Unit in Last Place) Analysis
=============================================================================#

"""
    ulp_distance(x::T, y::T) where {T<:AbstractFloat} -> Float64

Calculate the distance between two floating-point numbers in Units in the Last Place (ULP).

ULP distance measures how many representable floating-point numbers lie between x and y,
providing a hardware-independent measure of floating-point accuracy.

# Arguments
- `x::T`, `y::T`: Two floating-point numbers of the same type

# Returns  
- `Float64`: Distance in ULPs (can be fractional)

# Examples
```julia
julia> x = 1.0
julia> y = nextfloat(x)
julia> ulp_distance(x, y)
1.0

julia> ulp_distance(1.0, 1.0 + eps(Float64))
1.0
```

# Mathematical Background
For two floating-point numbers a and b, the ULP distance is:
distance = |a - b| / ULP(max(|a|, |b|))

where ULP(x) is the spacing between consecutive representable numbers at magnitude x.

# Implementation Notes
Handles special cases including subnormal numbers, infinities, and NaN values.
Returns Inf for infinite inputs and NaN when either input is NaN.
"""
function ulp_distance(x::T, y::T) where {T<:AbstractFloat}
    # Handle special cases
    if isnan(x) || isnan(y)
        return NaN
    end
    
    if isinf(x) || isinf(y)
        return isinf(x) && isinf(y) && sign(x) == sign(y) ? 0.0 : Inf
    end
    
    if x == y
        return 0.0
    end
    
    # Calculate ULP at the larger magnitude
    max_abs = max(abs(x), abs(y))
    ulp_value = eps(max_abs)
    
    # Handle case where ULP is zero (shouldn't happen with proper IEEE 754)
    if ulp_value == 0
        return Inf
    end
    
    return Float64(abs(x - y) / ulp_value)
end

"""
    ulp_analysis(computed::T, exact::T) where {T<:AbstractFloat} -> ULPInfo{T}

Comprehensive ULP analysis comparing computed and exact values.

# Arguments
- `computed::T`: Computed floating-point result
- `exact::T`: Exact or reference value

# Returns
- `ULPInfo{T}`: Complete ULP analysis including distance and relative error

# Examples
```julia
julia> computed = sin(π/4)  # Computed sine
julia> exact = √2/2        # Exact value  
julia> analysis = ulp_analysis(computed, exact)
julia> analysis.ulp_distance
0.8944271909999159
```
"""
function ulp_analysis(computed::T, exact::T) where {T<:AbstractFloat}
    ulp_val = eps(max(abs(computed), abs(exact)))
    ulp_dist = ulp_distance(computed, exact)
    
    # Calculate relative error as fraction of ULP
    if exact == zero(T)
        rel_error = abs(computed) == zero(T) ? 0.0 : Inf
    else
        rel_error = Float64(abs(computed - exact) / abs(exact))
    end
    
    return ULPInfo{T}(ulp_val, ulp_dist, rel_error)
end

#=============================================================================
Rounding Error Analysis
=============================================================================#

"""
    analyze_rounding_error(operation::Function, inputs::Tuple, ::Type{T}; 
                          reference_type::Type=BigFloat, 
                          reference_precision::Int=256) where {T<:AbstractFloat} -> PrecisionAnalysis{T}

Analyze rounding error in a floating-point operation by comparing with high-precision reference.

# Arguments
- `operation::Function`: Mathematical operation to analyze
- `inputs::Tuple`: Input arguments for the operation  
- `T::Type{<:AbstractFloat}`: Target floating-point type for analysis
- `reference_type::Type`: High-precision type for reference computation (default: BigFloat)
- `reference_precision::Int`: Precision in bits for reference computation (default: 256)

# Returns
- `PrecisionAnalysis{T}`: Comprehensive error analysis

# Examples
```julia
julia> # Analyze sin(π) computation error
julia> analysis = analyze_rounding_error(sin, (π,), Float64)
julia> analysis.significant_digits
15

julia> # Analyze subtraction prone to cancellation
julia> x, y = 1.0000001, 1.0000000  
julia> analysis = analyze_rounding_error(-, (x, y), Float64)
julia> analysis.precision_loss
0.23
```
"""
function analyze_rounding_error(operation::Function, inputs::Tuple, ::Type{T}; 
                               reference_type::Type=BigFloat, 
                               reference_precision::Int=256) where {T<:AbstractFloat}
    
    # Convert inputs to target type
    inputs_T = map(x -> convert(T, x), inputs)
    
    # Compute with target precision
    computed = operation(inputs_T...)
    
    # Compute high-precision reference
    if reference_type == BigFloat
        old_precision = precision(BigFloat)
        setprecision(BigFloat, reference_precision)
        try
            inputs_ref = map(x -> convert(BigFloat, x), inputs)
            theoretical = convert(T, operation(inputs_ref...))
        finally
            setprecision(BigFloat, old_precision)
        end
    else
        inputs_ref = map(x -> convert(reference_type, x), inputs)
        theoretical = convert(T, operation(inputs_ref...))
    end
    
    # Error analysis
    abs_error = abs(computed - theoretical)
    
    if theoretical == zero(T)
        rel_error = abs_error == zero(T) ? 0.0 : Inf
        sig_digits = abs_error == zero(T) ? typemax(Int) : 0
    else
        rel_error = Float64(abs_error / abs(theoretical))
        # Estimate significant digits
        sig_digits = rel_error > 0 ? max(0, -floor(Int, log10(rel_error))) : typemax(Int)
    end
    
    # Estimate precision loss (as fraction of available precision)
    max_precision = precision(T) # bits of precision
    if rel_error > 0
        lost_bits = -log2(rel_error)
        precision_loss = max(0.0, 1.0 - lost_bits / max_precision)
    else
        precision_loss = 0.0
    end
    
    return PrecisionAnalysis{T}(
        first(inputs_T), computed, theoretical,
        abs_error, rel_error, sig_digits, precision_loss
    )
end

#=============================================================================
Precision Loss Detection
=============================================================================#

"""
    detect_precision_loss(x::T, threshold::Float64=0.1) where {T<:AbstractFloat} -> Bool

Detect significant precision loss in a floating-point value.

Identifies when a computed value has lost a significant fraction of its representable precision,
which often indicates numerical instability or catastrophic cancellation.

# Arguments
- `x::T`: Floating-point value to analyze
- `threshold::Float64`: Precision loss threshold (0.0 to 1.0, default: 0.1)

# Returns
- `Bool`: true if significant precision loss detected

# Examples
```julia
julia> x = 1e-15  # Very small number, potential precision issues
julia> detect_precision_loss(x)
false

julia> # Simulate catastrophic cancellation
julia> a, b = 1.0000001, 1.0000000
julia> result = a - b  # Should be 1e-7 but may have errors
julia> detect_precision_loss(result, 0.05)  # Check with 5% threshold
```

# Implementation Notes
Uses relative magnitude analysis and ULP positioning to detect when a number
is suspiciously close to the limits of floating-point precision.
"""
function detect_precision_loss(x::T, threshold::Float64=0.1) where {T<:AbstractFloat}
    # Handle special cases
    if !isfinite(x)
        return false  # Inf/NaN are not precision loss in this context
    end
    
    if x == zero(T)
        return false  # Exact zero is fine
    end
    
    # Get the ULP at this value
    ulp_x = eps(x)
    
    # Check if value is suspiciously close to a power of 2 boundary
    # This often indicates precision loss from subtraction
    log2_abs_x = log2(abs(x))
    fractional_part = log2_abs_x - floor(log2_abs_x)
    
    # If very close to 0 or 1 in log2 space, might indicate precision loss
    boundary_closeness = min(fractional_part, 1.0 - fractional_part)
    
    # Compare with machine epsilon scaled by magnitude
    relative_ulp = ulp_x / abs(x)
    
    # Detect precision loss if:
    # 1. Value is very close to a power-of-2 boundary AND
    # 2. Relative ULP is large (indicating low precision)
    precision_loss_indicator = boundary_closeness < 0.01 && relative_ulp > threshold
    
    return precision_loss_indicator
end

"""
    measure_precision_loss(computed::T, reference::T) where {T<:AbstractFloat} -> Float64

Quantify precision loss by comparing computed result with reference value.

# Arguments
- `computed::T`: Computed result  
- `reference::T`: Reference or exact value

# Returns
- `Float64`: Fraction of precision lost (0.0 = no loss, 1.0 = complete loss)

# Examples
```julia
julia> computed = 0.1 + 0.2  # Has rounding error
julia> reference = 0.3       # Exact result
julia> measure_precision_loss(computed, reference)
0.036
```
"""
function measure_precision_loss(computed::T, reference::T) where {T<:AbstractFloat}
    if reference == zero(T)
        return computed == zero(T) ? 0.0 : 1.0
    end
    
    rel_error = Float64(abs(computed - reference) / abs(reference))
    
    if rel_error == 0.0
        return 0.0
    end
    
    # Estimate bits of precision lost
    bits_lost = -log2(rel_error)
    total_bits = precision(T)
    
    return max(0.0, min(1.0, 1.0 - bits_lost / total_bits))
end

#=============================================================================
Catastrophic Cancellation Detection
=============================================================================#

"""
    detect_cancellation(x::T, y::T, result::T; threshold::Float64=0.5) where {T<:AbstractFloat} -> Bool

Detect catastrophic cancellation in subtraction operations.

Catastrophic cancellation occurs when subtracting two nearly equal numbers, potentially
causing complete loss of precision in the result.

# Arguments
- `x::T`, `y::T`: Operands in subtraction x - y
- `result::T`: Result of the subtraction
- `threshold::Float64`: Relative magnitude threshold for detection (default: 0.5)

# Returns
- `Bool`: true if catastrophic cancellation detected

# Examples
```julia
julia> x, y = 1.000000001, 1.000000000
julia> result = x - y
julia> detect_cancellation(x, y, result)
true

julia> x, y = 2.0, 1.0  # Well-separated values
julia> result = x - y
julia> detect_cancellation(x, y, result)  
false
```

# Mathematical Background
Cancellation is detected when:
1. |x| ≈ |y| (operands have similar magnitude)
2. |result| << min(|x|, |y|) (result is much smaller than operands)
3. Precision analysis indicates significant error amplification

# Implementation Notes
Uses multiple heuristics including magnitude ratios, ULP analysis, and 
relative error estimation to reliably detect problematic cancellation.
"""
function detect_cancellation(x::T, y::T, result::T; threshold::Float64=0.5) where {T<:AbstractFloat}
    # Handle special cases
    if !isfinite(x) || !isfinite(y) || !isfinite(result)
        return false
    end
    
    if x == y
        return result != zero(T)  # Should be exactly zero
    end
    
    # Check magnitude similarity of operands
    max_mag = max(abs(x), abs(y))
    min_mag = min(abs(x), abs(y))
    
    if max_mag == zero(T)
        return false  # Both zero
    end
    
    # Ratio of operand magnitudes
    magnitude_ratio = min_mag / max_mag
    
    # Check if operands are similar in magnitude
    if magnitude_ratio < threshold
        return false  # Not similar enough for cancellation
    end
    
    # Check if result is much smaller than operands (main cancellation indicator)
    if abs(result) == zero(T)
        # Perfect cancellation - check if it should be exactly zero
        return abs(x - y) > eps(max_mag)
    end
    
    result_ratio = abs(result) / max_mag
    
    # Catastrophic cancellation if result is orders of magnitude smaller
    # and we have similar-magnitude operands
    cancellation_detected = (magnitude_ratio > threshold) && (result_ratio < sqrt(eps(T)))
    
    return cancellation_detected
end

"""
    analyze_subtraction_stability(x::T, y::T) where {T<:AbstractFloat} -> NamedTuple

Analyze numerical stability of subtraction x - y.

# Arguments
- `x::T`, `y::T`: Values to subtract

# Returns
- `NamedTuple`: Analysis including condition number, expected error, and stability classification

# Examples
```julia
julia> analysis = analyze_subtraction_stability(1.0000001, 1.0000000)
julia> analysis.condition_number
1.0000001e7

julia> analysis.stability_class
:ill_conditioned
```
"""
function analyze_subtraction_stability(x::T, y::T) where {T<:AbstractFloat}
    result = x - y
    
    # Condition number for subtraction
    if result == zero(T)
        condition_num = Inf
    else
        condition_num = max(abs(x), abs(y)) / abs(result)
    end
    
    # Expected relative error amplification  
    expected_error = condition_num * eps(T)
    
    # Classify stability
    if condition_num < 100
        stability = :well_conditioned
    elseif condition_num < 1e6
        stability = :moderately_conditioned  
    else
        stability = :ill_conditioned
    end
    
    # Check for cancellation
    has_cancellation = detect_cancellation(x, y, result)
    
    return (
        condition_number = condition_num,
        expected_relative_error = expected_error,
        stability_class = stability,
        has_cancellation = has_cancellation,
        result = result
    )
end

#=============================================================================
Floating-Point Format Analysis
=============================================================================#

"""
    float_format_info(::Type{T}) where {T<:AbstractFloat} -> FloatFormatInfo{T}

Extract comprehensive IEEE 754 format characteristics for floating-point type T.

Provides complete information about the binary representation, precision, and range
characteristics of Julia's floating-point types.

# Arguments
- `T::Type{<:AbstractFloat}`: Floating-point type to analyze

# Returns
- `FloatFormatInfo{T}`: Complete format specification

# Examples
```julia
julia> info = float_format_info(Float64)
julia> info.mantissa_bits
53

julia> info.exponent_bits  
11

julia> float_format_info(Float32).total_bits
32
```

# Supported Types
- `Float16`: IEEE 754 binary16 (half precision)
- `Float32`: IEEE 754 binary32 (single precision) 
- `Float64`: IEEE 754 binary64 (double precision)
- `BigFloat`: Arbitrary precision (characteristics depend on current precision setting)

# Implementation Notes
For BigFloat, returns current precision settings rather than fixed IEEE 754 characteristics.
All other types follow exact IEEE 754 specifications.
"""
function float_format_info(::Type{T}) where {T<:AbstractFloat}
    if T == Float16
        return FloatFormatInfo{T}(
            "Float16", 16, 1, 5, 11, 15, -14, 15
        )
    elseif T == Float32
        return FloatFormatInfo{T}(
            "Float32", 32, 1, 8, 24, 127, -126, 127  
        )
    elseif T == Float64
        return FloatFormatInfo{T}(
            "Float64", 64, 1, 11, 53, 1023, -1022, 1023
        )
    elseif T == BigFloat
        prec = precision(BigFloat)
        # BigFloat uses arbitrary precision, estimate equivalent characteristics
        return FloatFormatInfo{T}(
            "BigFloat", Int(prec + 32), 1, 32, Int(prec), 0, -typemax(Int32), typemax(Int32)
        )
    else
        # Generic fallback for unknown floating-point types
        return FloatFormatInfo{T}(
            string(T), 0, 1, 0, 0, 0, 0, 0
        )
    end
end

float_format_info(x::T) where {T<:AbstractFloat} = float_format_info(T)

#=============================================================================
Bit-Level Analysis
=============================================================================#

"""
    bit_analysis(x::T) where {T<:AbstractFloat} -> NamedTuple

Extract and analyze the bit-level representation of a floating-point number.

Provides detailed breakdown of sign, exponent, and mantissa components according
to IEEE 754 binary representation standards.

# Arguments
- `x::T`: Floating-point number to analyze

# Returns
- `NamedTuple`: Bit-level analysis including sign, exponent, mantissa, and derived properties

# Examples
```julia
julia> analysis = bit_analysis(1.5)
julia> analysis.sign_bit
0

julia> analysis.exponent_value
1023  # Biased exponent for Float64

julia> analysis.mantissa_fraction
0.5   # Fractional part of mantissa
```
"""
function bit_analysis(x::T) where {T<:AbstractFloat}
    if T == BigFloat
        # BigFloat doesn't have standard bit representation
        return (
            bit_string = string(x),
            sign_bit = signbit(x) ? 1 : 0,
            exponent_value = isfinite(x) ? exponent(x) : 0,
            mantissa_value = isfinite(x) ? significand(x) : zero(T),
            is_normalized = isfinite(x) && !issubnormal(x)
        )
    end
    
    # Get bit string representation
    bit_str = bitstring(x)
    
    # Extract components based on type
    format_info = float_format_info(T)
    
    sign_bit = bit_str[1] == '1' ? 1 : 0
    exp_bits = bit_str[2:(1+format_info.exponent_bits)]
    mantissa_bits = bit_str[(2+format_info.exponent_bits):end]
    
    # Parse exponent
    exp_value = parse(Int, exp_bits, base=2)
    biased_exp = exp_value - format_info.bias
    
    # Parse mantissa
    mantissa_int = parse(UInt64, mantissa_bits, base=2)
    mantissa_frac = mantissa_int / (UInt64(1) << length(mantissa_bits))
    
    # Determine number properties
    is_zero = (exp_value == 0 && mantissa_int == 0)
    is_subnormal = (exp_value == 0 && mantissa_int != 0)
    is_infinity = (exp_value == (1 << format_info.exponent_bits) - 1 && mantissa_int == 0)
    is_nan = (exp_value == (1 << format_info.exponent_bits) - 1 && mantissa_int != 0)
    is_normalized = !is_zero && !is_subnormal && !is_infinity && !is_nan
    
    return (
        bit_string = bit_str,
        sign_bit = sign_bit,
        exponent_bits = exp_bits,
        mantissa_bits = mantissa_bits,
        exponent_value = exp_value,
        biased_exponent = biased_exp,
        mantissa_integer = mantissa_int,
        mantissa_fraction = mantissa_frac,
        is_zero = is_zero,
        is_subnormal = is_subnormal,
        is_infinity = is_infinity,
        is_nan = is_nan,
        is_normalized = is_normalized
    )
end

#=============================================================================
Special Value Analysis
=============================================================================#

"""
    special_value_info(x::T) where {T<:AbstractFloat} -> NamedTuple

Analyze special floating-point values (NaN, Inf, subnormal, etc.).

Provides comprehensive classification and analysis of special floating-point values
according to IEEE 754 standards.

# Arguments
- `x::T`: Floating-point value to analyze

# Returns
- `NamedTuple`: Complete special value analysis

# Examples
```julia
julia> special_value_info(NaN)
(class = :nan, is_signaling = false, ...)

julia> special_value_info(1e-320)  # Subnormal for Float64
(class = :subnormal, ...)
```
"""
function special_value_info(x::T) where {T<:AbstractFloat}
    # Classify the value
    if isnan(x)
        value_class = :nan
        is_signaling = false  # Julia typically uses quiet NaN
    elseif isinf(x)
        value_class = x > 0 ? :positive_infinity : :negative_infinity
        is_signaling = false
    elseif x == zero(T)
        value_class = signbit(x) ? :negative_zero : :positive_zero
        is_signaling = false
    elseif issubnormal(x) 
        value_class = :subnormal
        is_signaling = false
    else
        value_class = :normal
        is_signaling = false
    end
    
    # Additional properties
    is_finite = isfinite(x)
    is_special = !is_finite || x == zero(T) || issubnormal(x)
    sign_bit = signbit(x)
    
    # Range analysis
    if isfinite(x) && x != zero(T)
        magnitude_class = if abs(x) < floatmin(T)
            :subnormal_range
        elseif abs(x) > floatmax(T) / 2
            :near_overflow  
        else
            :normal_range
        end
    else
        magnitude_class = :special
    end
    
    return (
        value = x,
        class = value_class,
        is_finite = is_finite,
        is_special = is_special,
        is_signaling = is_signaling,
        sign_bit = sign_bit,
        magnitude_class = magnitude_class,
        is_zero = x == zero(T),
        is_subnormal = issubnormal(x),
        is_nan = isnan(x),
        is_infinite = isinf(x)
    )
end

#=============================================================================
Precision Bounds Analysis
=============================================================================#

"""
    precision_bounds(::Type{T}) where {T<:AbstractFloat} -> NamedTuple

Calculate theoretical precision bounds and limits for floating-point type T.

Provides comprehensive analysis of representational limits, precision bounds, and
theoretical error bounds for floating-point computations.

# Arguments
- `T::Type{<:AbstractFloat}`: Floating-point type to analyze

# Returns
- `NamedTuple`: Complete precision bounds analysis

# Examples
```julia
julia> bounds = precision_bounds(Float64)
julia> bounds.decimal_digits
15

julia> bounds.safe_computation_range
(1.0842021724855044e-19, 9.007199254740992e15)
```
"""
function precision_bounds(::Type{T}) where {T<:AbstractFloat}
    format_info = float_format_info(T)
    
    # Basic precision metrics
    machine_eps = eps(T)
    unit_roundoff = machine_eps / T(2)
    
    # Decimal precision estimate
    decimal_digits = floor(Int, (format_info.mantissa_bits - 1) * log10(2))
    
    # Range limits
    min_pos_normal = floatmin(T)
    max_finite = floatmax(T)
    min_pos_subnormal = nextfloat(zero(T))
    
    # Safe computation ranges (avoid overflow/underflow)
    safe_min = sqrt(min_pos_normal)
    safe_max = sqrt(max_finite)
    
    # ULP spacing analysis
    ulp_at_one = eps(one(T))
    ulp_near_zero = min_pos_subnormal
    
    # Theoretical error bounds
    relative_error_bound = unit_roundoff
    absolute_error_bound = machine_eps
    
    return (
        type_name = format_info.type_name,
        machine_epsilon = machine_eps,
        unit_roundoff = unit_roundoff,
        decimal_digits = decimal_digits,
        mantissa_bits = format_info.mantissa_bits,
        min_positive_normal = min_pos_normal,
        max_finite_value = max_finite,
        min_positive_subnormal = min_pos_subnormal,
        safe_computation_range = (safe_min, safe_max),
        ulp_at_one = ulp_at_one,
        ulp_near_zero = ulp_near_zero,
        theoretical_relative_error_bound = relative_error_bound,
        theoretical_absolute_error_bound = absolute_error_bound
    )
end

precision_bounds(x::T) where {T<:AbstractFloat} = precision_bounds(T)

#=============================================================================
Comparative Analysis
=============================================================================#

"""
    compare_precision(::Type{T1}, ::Type{T2}) where {T1<:AbstractFloat, T2<:AbstractFloat} -> NamedTuple

Compare precision characteristics between two floating-point types.

# Arguments
- `T1`, `T2`: Floating-point types to compare

# Returns
- `NamedTuple`: Detailed comparison of precision characteristics

# Examples
```julia
julia> comparison = compare_precision(Float32, Float64)
julia> comparison.precision_ratio
2.2737367544323206e-13  # Float32 eps / Float64 eps
```
"""
function compare_precision(::Type{T1}, ::Type{T2}) where {T1<:AbstractFloat, T2<:AbstractFloat}
    bounds1 = precision_bounds(T1)
    bounds2 = precision_bounds(T2)
    
    eps_ratio = Float64(bounds1.machine_epsilon) / Float64(bounds2.machine_epsilon)
    precision_ratio = bounds1.mantissa_bits / bounds2.mantissa_bits
    range_ratio = Float64(bounds1.max_finite_value) / Float64(bounds2.max_finite_value)
    
    better_precision = bounds1.mantissa_bits > bounds2.mantissa_bits ? T1 : T2
    wider_range = bounds1.max_finite_value > bounds2.max_finite_value ? T1 : T2
    
    return (
        type1 = bounds1.type_name,
        type2 = bounds2.type_name,
        epsilon_ratio = eps_ratio,
        precision_bit_ratio = precision_ratio,
        range_ratio = range_ratio,
        better_precision_type = string(better_precision),
        wider_range_type = string(wider_range),
        decimal_digits_1 = bounds1.decimal_digits,
        decimal_digits_2 = bounds2.decimal_digits
    )
end

#=============================================================================
Numerical Stability Analysis
=============================================================================#

"""
    numerical_stability_check(operation::Function, inputs::Vector{T}; 
                             perturbation_scale::Float64=1e-12) where {T<:AbstractFloat} -> NamedTuple

Analyze numerical stability of an operation by testing sensitivity to input perturbations.

# Arguments
- `operation::Function`: Function to test
- `inputs::Vector{T}`: Input values
- `perturbation_scale::Float64`: Relative perturbation magnitude

# Returns
- `NamedTuple`: Stability analysis results

# Examples
```julia
julia> stability = numerical_stability_check(x -> x[1] - x[2], [1.0000001, 1.0000000])
julia> stability.condition_estimate
1.0000001e7
```
"""
function numerical_stability_check(operation::Function, inputs::Vector{T}; 
                                  perturbation_scale::Float64=1e-12) where {T<:AbstractFloat}
    
    # Baseline computation
    baseline_result = operation(inputs)
    
    # Test multiple random perturbations
    n_tests = 10
    max_relative_change = 0.0
    condition_estimates = Float64[]
    
    for i in 1:n_tests
        # Create perturbed inputs
        perturbations = [randn() * perturbation_scale for _ in inputs]
        perturbed_inputs = inputs .+ inputs .* perturbations
        
        # Compute with perturbed inputs
        perturbed_result = operation(perturbed_inputs)
        
        # Analyze sensitivity
        if baseline_result != zero(T)
            relative_input_change = maximum(abs.(perturbations))
            relative_output_change = abs(perturbed_result - baseline_result) / abs(baseline_result)
            
            if relative_input_change > 0
                condition_est = relative_output_change / relative_input_change
                push!(condition_estimates, condition_est)
                max_relative_change = max(max_relative_change, relative_output_change)
            end
        end
    end
    
    # Summary statistics
    avg_condition = isempty(condition_estimates) ? 0.0 : sum(condition_estimates) / length(condition_estimates)
    max_condition = isempty(condition_estimates) ? 0.0 : maximum(condition_estimates)
    
    # Classify stability
    if avg_condition < 10
        stability_class = :stable
    elseif avg_condition < 1000  
        stability_class = :moderately_stable
    else
        stability_class = :unstable
    end
    
    return (
        baseline_result = baseline_result,
        condition_estimate = avg_condition,
        max_condition = max_condition,
        max_relative_change = max_relative_change,
        stability_class = stability_class,
        n_tests = n_tests
    )
end

#=============================================================================
Report Generation
=============================================================================#

"""
    format_analysis_report(analyses::Dict; title::String="Floating-Point Analysis Report") -> String

Generate a comprehensive formatted report from analysis results.

# Arguments
- `analyses::Dict`: Dictionary of analysis results from various functions
- `title::String`: Report title

# Returns
- `String`: Formatted analysis report

# Examples
```julia
julia> analyses = Dict(
    "machine_epsilon" => machine_epsilon_info(Float64),
    "precision_bounds" => precision_bounds(Float64)
)
julia> report = format_analysis_report(analyses)
julia> println(report)
```
"""
function format_analysis_report(analyses::Dict; title::String="Floating-Point Analysis Report")
    io = IOBuffer()
    
    println(io, "="^60)
    println(io, title)
    println(io, "="^60)
    println(io)
    
    for (section_name, analysis) in analyses
        println(io, "## ", uppercasefirst(replace(section_name, "_" => " ")))
        println(io, "-"^40)
        
        if isa(analysis, NamedTuple)
            for (key, value) in pairs(analysis)
                if isa(value, AbstractFloat)
                    println(io, @sprintf("  %-25s: %.6e", string(key), value))
                else
                    println(io, @sprintf("  %-25s: %s", string(key), string(value)))
                end  
            end
        else
            println(io, "  ", analysis)
        end
        
        println(io)
    end
    
    println(io, "="^60)
    println(io, "Report generated at ", now())
    println(io, "="^60)
    
    return String(take!(io))
end

#=============================================================================
Utility Functions
=============================================================================#

"""
    precision(::Type{T}) where {T<:AbstractFloat} -> Int

Get the precision (mantissa bits) for a floating-point type.

# Examples
```julia
julia> precision(Float64)
53

julia> precision(Float32)
24
```
"""
function Base.precision(::Type{T}) where {T<:AbstractFloat}
    if T == Float16
        return 11
    elseif T == Float32
        return 24
    elseif T == Float64
        return 53
    elseif T == BigFloat
        return precision(BigFloat)
    else
        return 0  # Unknown type
    end
end

"""
    issubnormal(x::T) where {T<:AbstractFloat} -> Bool

Check if a floating-point number is subnormal (denormalized).

# Examples
```julia
julia> issubnormal(1e-320)  # True for Float64
true

julia> issubnormal(1.0)
false
```
"""
function Base.issubnormal(x::T) where {T<:AbstractFloat}
    return isfinite(x) && x != zero(T) && abs(x) < floatmin(T)
end

#=============================================================================
Module End and Convenience Functions
=============================================================================#

"""
    analyze_float_comprehensive(x::T) where {T<:AbstractFloat} -> Dict

Perform comprehensive analysis of a single floating-point value.

# Arguments
- `x::T`: Floating-point value to analyze

# Returns
- `Dict`: Complete analysis results from all relevant functions

# Examples
```julia
julia> results = analyze_float_comprehensive(1.5)
julia> keys(results)
```
"""
function analyze_float_comprehensive(x::T) where {T<:AbstractFloat}
    results = Dict{String, Any}()
    
    results["type_info"] = float_format_info(T)
    results["machine_epsilon"] = machine_epsilon_info(T)
    results["precision_bounds"] = precision_bounds(T)
    results["bit_analysis"] = bit_analysis(x)
    results["special_value_info"] = special_value_info(x)
    
    return results
end

"""
    analyze_operation_precision(operation::Function, inputs::Tuple, ::Type{T}) where {T<:AbstractFloat} -> Dict

Comprehensive precision analysis for a mathematical operation.

# Arguments
- `operation::Function`: Mathematical operation to analyze
- `inputs::Tuple`: Input arguments
- `T::Type{<:AbstractFloat}`: Target floating-point type

# Returns
- `Dict`: Complete operation analysis

# Examples
```julia
julia> results = analyze_operation_precision(sin, (π/4,), Float64)
julia> results["rounding_error"].significant_digits
```
"""
function analyze_operation_precision(operation::Function, inputs::Tuple, ::Type{T}) where {T<:AbstractFloat}
    results = Dict{String, Any}()
    
    # Convert inputs and compute result
    inputs_T = map(x -> convert(T, x), inputs)
    result = operation(inputs_T...)
    
    results["inputs"] = inputs_T
    results["result"] = result
    results["rounding_error"] = analyze_rounding_error(operation, inputs, T)
    results["result_analysis"] = analyze_float_comprehensive(result)
    
    # If it's a subtraction, check for cancellation
    if length(inputs_T) == 2 && operation == (-)
        results["subtraction_stability"] = analyze_subtraction_stability(inputs_T[1], inputs_T[2])
        results["cancellation_detected"] = detect_cancellation(inputs_T[1], inputs_T[2], result)
    end
    
    return results
end

# Add now() function compatibility for report generation
if !isdefined(Base, :now)
    now() = "$(Dates.now())"
end

end # module FloatingPointAnalysis
